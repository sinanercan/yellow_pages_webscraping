{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f65f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70b0b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Yeni klasör\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from random import randint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4b342",
   "metadata": {},
   "source": [
    "This project has been developed for web scraping from https://www.yellowpages.ca/ website. In order to use the programme, the chrome driver must be compatible with the related version of selenium package. For this reason, the lines between 3-10 in the script have been added so that the download and installation process can be performed automatically. The code asks the user to enter two different keywords to generate search results on the yellowpages page:\n",
    "\n",
    "(1) A keyword what you want to search on yellowpages website (variable name: what).  You can browse yellowpages website first to determine what keywords you want to search on. Besides, the code does not sensitive upper and lower cases, and please do not include special characters in search results.\n",
    "(2) A keyword where you want to search on yellowpages website (variable name: where).This variable helps you to restrict the search results for specific locations (e.g. a state or city). \n",
    "\n",
    "Note: In this script, entire searching results are listed and the informations listed below are scrapped from search results.Finally, the results are saved as \".csv\" file. \n",
    "1- Category\n",
    "2- Postcode\n",
    "3- Province\n",
    "4- City (if any)\n",
    "5- Street\n",
    "6- Name\n",
    "7- Phone\n",
    "8- Site (if any)\n",
    "9- Review (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5be95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class yellow_page_ca_scraper:\n",
    "    \n",
    "    def open_yellow_page_ca(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.headless = True\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument(\"--disable-setuid-sandbox\")\n",
    "        options.add_argument(\"--disable-setuid-sandbox\")\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        chrome_deriver_manager = ChromeDriverManager()\n",
    "        driver = webdriver.Chrome(chrome_deriver_manager.install(), options=options)\n",
    "        page = driver.get('https://www.yellowpages.ca/')\n",
    "        search_what = driver.find_element(By.ID, \"whatwho\")\n",
    "        search_what.send_keys(what)\n",
    "        search_where = driver.find_element(By.ID, \"where\")\n",
    "        search_where.send_keys(where)\n",
    "        search = driver.find_element(\"xpath\",\"//*[@id='inputForm']/div[2]/div[2]/div/button/span[1]\")\n",
    "        search.submit()\n",
    "        time.sleep(randint(7,11))\n",
    "        number_of_pages = driver.find_element(By.CLASS_NAME,\"pageCount\").text\n",
    "        pattern1 = r'^\\d\\s/\\s'\n",
    "        match = (re.search(pattern1, number_of_pages))\n",
    "        number_of_pages = number_of_pages[match.end():]\n",
    "        base_url = driver.current_url\n",
    "        pattern = r'\\d+'\n",
    "        match = (re.search(pattern, base_url))\n",
    "        base_url1 = base_url[:match.start()]\n",
    "        base_url2 = base_url[match.end():]\n",
    "        time.sleep(randint(3,4))\n",
    "        category = driver.find_element(By.XPATH,\"//*[@id='jsListingMerchantCards']/div[1]/h1/strong[1]\").text\n",
    "        province = driver.find_element(By.XPATH,\"//*[@id='jsListingMerchantCards']/div[1]/h1/strong[2]\").text\n",
    "        pattern2 = r'\\b[A-Z]{2,}'\n",
    "        match2 = (re.search(pattern2, province))\n",
    "        province = province[match2.start():match2.end()]\n",
    "        return driver, number_of_pages, base_url1, base_url2, category, province\n",
    "    \n",
    "    def get_page_results_info(self):\n",
    "        lists = []\n",
    "        bar = tqdm(range(1,int(number_of_pages)+1))\n",
    "        for page in bar:\n",
    "            bar.set_description(\"Processing of page {}\".format(page))\n",
    "            base_url = base_url1 + \"{}\".format(str(page)) + base_url2\n",
    "            r = requests.get(base_url)\n",
    "            parsedHTML = bs(r.text, \"html.parser\")\n",
    "            links_of_page = parsedHTML.find_all('div', class_ = 'listing__content__wrap--flexed jsGoToMp')\n",
    "            for current_div in links_of_page:\n",
    "                name = current_div.find('a', class_ = 'listing__name--link listing__link jsListingName').text.strip()\n",
    "                try:\n",
    "                    address = current_div.find('span', class_ ='listing__address--full').text.strip()\n",
    "                except:\n",
    "                    address = 'There is no address information'   \n",
    "                try:\n",
    "                    postcode = current_div.find(\"span\", {\"itemprop\" : \"postalCode\"}).text\n",
    "                except:\n",
    "                    postcode = 'There is no postcode information'     \n",
    "                try:\n",
    "                    city = current_div.find(\"span\", {\"itemprop\" : \"addressLocality\"}).text\n",
    "                except:\n",
    "                    city = 'There is no city information'  \n",
    "                try:\n",
    "                    website = current_div.find(\"li\", \"mlr__item mlr__item--website\").a[\"href\"]\n",
    "                    websiteRedirect = website.find(\"redirect=\")\n",
    "                    website = website[websiteRedirect+9:]\n",
    "                    website = website.replace(\"%3A\", \":\")\n",
    "                    website = website.replace(\"%2F\", \"/\")      \n",
    "                except:\n",
    "                    website = 'There is no website'\n",
    "                try:\n",
    "                    tel = current_div.find(\"li\", \"mlr__item mlr__item--more mlr__item--phone jsMapBubblePhone\").text.strip().replace('\\n', '')\n",
    "                    tel = str(tel)\n",
    "                    tel = tel[12:]\n",
    "                except:\n",
    "                    tel = 'There is no telephone number'\n",
    "                try:\n",
    "                    rating = current_div.find('span', class_ = 'ypStars jsReviewsChart')[\"title\"]\n",
    "                except:\n",
    "                    rating = 'There is no rating value'\n",
    "                info = {\n",
    "                        'Category':category,\n",
    "                        'Postcode':postcode,\n",
    "                        'Province':province,\n",
    "                        'City':city,\n",
    "                        'Street':address,\n",
    "                        'Name':name,\n",
    "                        'Phone':tel,\n",
    "                        'Site':website,\n",
    "                        'Review':rating    \n",
    "                        }\n",
    "                lists.append(info)\n",
    "        return lists\n",
    "    def save_csv(self): \n",
    "        #pd.set_option('display.max_rows', None)\n",
    "        df = pd.DataFrame(lists)\n",
    "        df.to_csv('yellow_page_ca_results.csv', index=False)\n",
    "        return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736c48fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a keyword what you want to search on Yellow Pages:restaurant\n",
      "Enter a keyword where you want to search on Yellow Pages:toronto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing of page 354: 100%|████████████████████████████████████████████████████████| 354/354 [12:49<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    scraper = yellow_page_ca_scraper()\n",
    "    what = input('Enter a keyword what you want to search on Yellow Pages:')\n",
    "    where = input('Enter a keyword where you want to search on Yellow Pages:')\n",
    "    driver, number_of_pages, base_url1, base_url2, category, province = scraper.open_yellow_page_ca()\n",
    "    lists = scraper.get_page_results_info()\n",
    "    scraper.save_csv()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
